---
title: "p8105_hw6_qz2266"
author: "Qing Zhou"
date: "2022-11-30"
output: github_document
---

```{r packages}
library(tidyverse)
library(dplyr)
library(rvest)
library(purrr)
library(ggplot2)
library(modelr)
library(mgcv)
library(patchwork)
library(viridis)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


### Problem 2

```{r read and tidy data}
# read data
homicide = 
  read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv", na = c("","NA","Unknown")) %>%
  
# create a city_state variable, a binary solution variable and make sure victim_age is numeric
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = case_when(
           disposition == "Closed without arrest" ~ 0,
           disposition == "Open/No arrest"        ~ 0,
           disposition == "Closed by arrest"      ~ 1),
    victim_age = as.numeric(victim_age)
  ) %>% 
  
# Omit 4 cities and limit the races
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Dallas, TX",
    city_state != "Phoenix, AZ",
    city_state != "Kansas City, MO",
    city_state != "Tulsa, AL") %>%
  filter(!is.na(victim_age)) %>%
  filter(!is.na(victim_sex)) %>%
  filter(!is.na(victim_race)) %>%
  filter(!is.na(resolution)) %>%
  filter(!is.na(city_state)) %>%
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```
    
#### Run glm for the city of Baltimore, MD

```{r run glm logistic regression on Baltimore}
# baltimore df
baltimore_df =
  homicide %>% 
  filter(city_state == "Baltimore, MD")

# run glm
baltimore_glm = baltimore_df %>% 
  glm(resolution ~ victim_age + victim_sex + victim_race, 
      data = ., family = binomial(link = "logit")) %>%
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    lower_CI = exp(estimate - 1.96*std.error),
    upper_CI = exp(estimate + 1.96*std.error),
    p_val = rstatix::p_format(p.value, digits = 2)
  ) %>% 
  select(term, OR, lower_CI, upper_CI, p_val) %>%
  filter(term == "victim_sexMale") %>%
  knitr::kable(digits = 3)
baltimore_glm
```

#### Run glm for each of the cities

```{r run glm for all cities}
city_df = 
  homicide %>% 
  nest(data = -city_state) %>% 
  mutate(
    raw_model = 
      map(data, ~glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(),data = .x)), 
    tidy_model = map(raw_model, broom::tidy)
  ) %>% 
  select(city_state, tidy_model) %>% 
  unnest(cols = tidy_model) %>%
  mutate(
     OR = exp(estimate),
     lower_CI = exp(estimate - 1.96*std.error),
     upper_CI = exp(estimate + 1.96*std.error)
  ) %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, term, OR, lower_CI, upper_CI)
   
city_df
```

#### Create a plot that shows the estimated ORs and CIs for each city.

```{r  plot}
city_df %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI)) + 
  labs(
    title = "Estimated ORs and CIs for Each City",
    x = "City, State",
    y = "Estimated Odds Ratio") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

**Comments on the plot:**

This plot shows us the city-specific odds ratio of solving homicides among male vs female victims, while keeping all other variables fixed. With odds ratio = 1, the odds of solved homicides among male victims is equals to that among female victims. From the plot we found:

1). New York, NY has the lowest estimated odds ratio while Albuquerque, NM has the highest.

2). For the majority of cities, the odds of solved homicides is lower when the victims are male, compared to when victims are female. Or we can say for most cities, victims in solved homicides are more likely to be female than male, since their odds ratio are below 1. Only in less than 10 cities, such as Fresno, CA, when the victims are male, the possibility of homicides gets solved is higher than when the victims are female. 

3). Almost half of the cities show a statistically significant association between the victim being male and the likelihood of the homicide to go solved vs. the victim being female, since their CIs didn't include 1.



### Problem 3

```{r load and clean data}
birthweight = 
  read_csv("data/birthweight.csv", na = c("","NA","Unknown")) %>% 
  mutate( 
    babysex = as.factor(babysex),
    babysex = recode_factor(babysex,
                           "1" = "male",
                           "2" = "female"),
    frace = as.factor(frace),
    frace = recode_factor(frace,
                          "1" = "White",
                          "2" = "Black",
                          "3" = "Asian",
                          "4" = "Puerto Rican",
                          "8" = "Other"),
    malform = as.factor(malform),
    malform = recode_factor(malform,
                            "0" = "absent", 
                            "1" = "present"),
    mrace = as.factor(mrace),
    mrace = recode_factor(mrace,
                          "1" = "White",
                          "2" = "Black",
                          "3" = "Asian",
                      "4" = "Puerto Rican",
                      "8" = "Other")
    ) 
purrr::map(birthweight, ~ sum(is.na(.))) # check for missing data 
```

#### Propose a regression model for birthweight based on a hypothesized structure for the factors that underly birthweight.

```{r model building}
# use F-statistic for globally testing if ANY of the independent variables is related to the outcome.
bw_model_1 = birthweight %>% 
  lm(bwt ~ momage + ppbmi + wtgain + smoken, data = .) 
summary(bw_model_1)
bw_model_1 %>% 
  broom::tidy() %>% 
  knitr::kable(digit = 3)
```

**Description of my modeling process:** 

I built my regression model based on a hypothesized structure for the factors that underly birth weight.There are numerous research articles investigating the parental contribution to birth weight, especially the birth weight correlation for mother-child. My study was aimed to assess the birth weight of child and associated factors among mothers. Here I chose bwt: baby’s birth weight (grams) as outcome, regressed it on 4 properties of Mom, including 
- momage: mother’s age at delivery (years)
- ppbmi: mother’s pre-pregnancy BMI
- wtgain: mother’s weight gain during pregnancy (pounds)
- smoken: average number of cigarettes smoked per day during pregnancy.

**Comment on my model:**

Since the P value for the F-test of overall significance test is <2.2e-16, less than the significance level, we reject the null-hypothesis and conclude that this model provides a better fit than the intercept-only model, aka AT LEAST 1 independent variable is related to the outcome.

Moreover, the adjusted R-squared value is 0.1067, suggesting 11% variation in outcome is explained by the variation in independent variables.


####  Model diagnositcs: plots for residuals normality and for model residuals against fitted values

```{r plotting residuals normality}
# check the distribution of residuals
birthweight %>% 
  add_residuals(bw_model_1) %>%
      ggplot(aes(x = resid)) + geom_density()
```

```{r QQ_plot}
plot(bw_model_1, which = 2)
```

**Comments on the plot**:
As the first step of model diagnostic, I checked if the residual is normally distributed. 

In the distribution plot, residuals follow a normal distribution centered on 0. In QQ plot, we can see a straight line with some outliers but the extent of outliers is acceptable. Thus, based on these two plots, we concluded the basic assumption of residual normality is satisfied in this model.

```{r plotting residuals against fitted values}
birthweight %>% 
  add_residuals(bw_model_1) %>%
    add_predictions(bw_model_1) %>% 
      ggplot(aes(x = pred, y = resid)) + 
      geom_point() +
      geom_smooth(se = F, color = "red", method = "lm") +
      labs(
      title = "Residuals vs. Fitted",
      x = "Fitted values",
      y = "Residuals"
      ) +
      theme(plot.title = element_text(hjust = 0.5))
```

**Comments on the plot**:

Secondly, I checked residuals vs fitted values. This plot is used to detect unequal error variance (heteroscedasticity) and outliers.

From the plot we can see residuals values are symmetrically distributed and bounce around 0, which is their expected value. Residuals form a horizontal (linear) ‘band’ around zero. Therefore, from their random pattern, we concluded that the residuals have constant variance. Moreover, the plot shows a couple of ‘unusual’ values stand out from the random pattern, suggesting a few potential outliers.

#### Two alternative models

```{r alternative_models}
# main effects model
bw_model_2 =
  lm(bwt ~ blength + gaweeks, data = birthweight)
bw_model_2 %>% 
  broom::tidy() %>%
  knitr::kable(digit = 3)
plot(bw_model_2, which = 1)

# interactions model
bw_model_3 = 
  lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = birthweight)
bw_model_3 %>% 
  broom::tidy() %>%
  knitr::kable(digit = 3)
plot(bw_model_3, which = 1)
```

#### Cross validation of these three models

```{r cv_df, warning=FALSE}
# preforms the training / testing split
cv_df = 
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

#  fit models to training data and obtain corresponding RMSEs for the testing data
cv_df = 
  cv_df %>% 
  mutate(
   bw_model_1 = map(train, ~lm(bwt ~ momage + ppbmi + wtgain + smoken, data = .x)),
   bw_model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
   bw_model_3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = .x))
  ) %>% 
  mutate(
    rmse_model1 = map2_dbl(bw_model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(bw_model_2, test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(bw_model_3, test, ~rmse(model = .x, data = .y))
  )
```

```{r}
# plot the prediction error distribution for each model
predict_err =
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  stat_summary(fun = "median", color = "blue") +
  labs(
    x = "Model",
    y = "RMSE",
    title = "Distribution of three models' RMSE"
  )
predict_err

# the average rmse of each model
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  group_by(model) %>% 
  summarize(avg_rsme = mean(rmse))
```

```{r}
summary(bw_model_1)$adj.r.squared
summary(bw_model_2)$adj.r.squared
summary(bw_model_3)$adj.r.squared
```

**Comparing my model with the two others**: 

Based on the RMSE distribution of each model, the best model is model 3 which regresses birth weight on head circumference, length, sex, and all interactions, since it has the best RMSE distribution with the lowest value on average 100 different iterations of training and testing data. The second best model is model 2 which is the main effects only model. Model 1, the one I proposed, is the worst.  

Moreover, the adjusted R-squared of model 1, model 2 and model 3 are 0.1067, 0.5767 and 0.6844, respectively, also suggesting model 3 is better than model 2, and model 1 is the least favorable, in terms of goodness of fit. 


### Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 


